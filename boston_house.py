# -*- coding: utf-8 -*-
"""Boston House.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X83PJ7iMbHYPkUGYsVkb7D6kYFS24qF6

# **APRENDIZAGEM SUPERVISINADA: REGRESSÃO**

Este projeto tem por objetivo desenvolver um algoritmo de Machine learning para prever o valor do preço médio de casas em Boston.

Os dados foram extraidos do site do Kaggle

https://www.kaggle.com/schirmerchad/bostonhoustingmlnd
"""

import numpy as np
import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/housing.csv')

df.head()

"""**ATRIBUTOS PREVISORES**

RM: É o úmero médio de cômodos entre os imoveis no bairro.

LSTAT: É a porcentagem de proprietários no bairro considerado de "classe baixa" (proletariado).

PTRATIO: É a razão entre estudantes e professores nas escolas de ensino fundamental no bairro.


VARIAVEL ALVO

MEDV: Valor médio das casas
"""

df.shape

"""489 linhas
4 colunas
"""

# RELAÇÃO DA QUANTIDADE
df.isnull().sum()

"""Não há valor faltante"""

# object: string
# int64: inteiros
# float64: reais
# complex: complexos
df.dtypes

"""**DADOS ESTATISTICOS**"""

df.describe()

"""**ANÁLISE DOS OUTLIERS**"""

import plotly.express as px

boxplot = px.box(df, y="RM")
boxplot.show()

boxplot = px.box(df, y="LSTAT")
boxplot.show()

boxplot = px.box(df, y="PTRATIO")
boxplot.show()

boxplot = px.box(df, y="MEDV")
boxplot.show()

"""**ABAIXO ESTUDO DA CORRELAÇÃO LINEAR**"""

df.head(2)

"""**ATRIBUTOS PREVISORES**

**RM**: É o úmero médio de cômodos entre os imoveis no bairro.

**LSTAT**: É a porcentagem de proprietários no bairro considerado de "classe baixa" (proletariado).

**PTRATIO**: É a razão entre estudantes e professores nas escolas de ensino fundamental no bairro.

VARIAVEL ALVO

**MEDV**: Valor médio das casas
"""

import matplotlib.pyplot as plt

plt.scatter(df.RM, df.MEDV)
plt.title('Correlação Linear')
plt.xlabel('Quantidade Media de Comôdos')
plt.ylabel('Valor Médio')
plt.grid(False)

"""Correlção linear POSITIVA (crescente)"""

plt.scatter(df.LSTAT, df.MEDV)
plt.title('Correlção Linear')
plt.xlabel('Quantidade Classe Baixa (%)')
plt.ylabel('Valor Médio')
plt.grid(False)

"""correllção linear negativa (decrescente)"""

plt.scatter(df.PTRATIO, df.MEDV)
plt.title('Correlação Linar')
plt.xlabel('Estudante/Professores')
plt.ylabel('Valor Médio')
plt.grid(False)

import seaborn as sns

sns.pairplot(df);

"""**ABAIXO ANÁLISE DA NORMALIDADE**

Grafico QQ-Plot
"""

import scipy.stats as stats

stats.probplot(df.MEDV, dist="norm", plot=plt)
plt.title('Nomal Q-Q Plot')
plt.show()

import plotly.express as px

hist = px.histogram (df, x = "MEDV", nbins=60)
hist.update_layout(width=800, height=500, title_text='Média dos valores')
hist.show()

stats.probplot(df.RM, dist="norm", plot=plt)
plt.title('Normal Q-Q Plot')
plt.show()

hist = px.histogram (df, x = "RM", nbins=60)
hist.update_layout(width=800, height=500, title_text='Quantidade de comodos')
hist.show()

stats.probplot(df.LSTAT, dist="norm", plot=plt)
plt.title("Norma Q-Q Plot")
plt.show()

hist = px.histogram(df, x = "LSTAT", nbins=60)
hist.update_layout(width=800, height=500, title_text='Quantidade de Classe baixa (%)')
hist.show()

stats.probplot(df.PTRATIO, dist="norm", plot=plt)
plt.title("Normal Q-Q Plot")
plt.show()

hist = px.histogram(df, x = "PTRATIO", nbins=60)
hist.update_layout(width=800, height=500, title_text='Relação de Estudantes/Professores')
hist.show()

"""**ABAIXO TESTE DE SHAPIRO-WILK**

Ho = distribuição normal: p > 0.05

Ha = distribuição !=normal: p <= 0.05
"""

stats.shapiro(df.MEDV)

estatistica, p = stats.shapiro(df.MEDV)
print('Estatistica do teste: {}'.format(estatistica))
print('p-valor: {}'.format(p))

estatistca, p = stats.shapiro(df.RM)
print('Estatistica: {}'.format(estatistica))
print('p-valor: {}'.format(p))

estatistica, p = stats.shapiro(df.LSTAT)
print('Estatistica: {}'.format(estatistica))
print('P-valor: {}'.format(p))

estatistica, p = stats.shapiro(df.PTRATIO)
print('Estatistica: {}'.format(estatistica))
print('p-valor: {}'.format(p))

"""Teste Lilliefors (Kolmogorov_Sminorv)

Ho = Distribuição normal: p>0.05

Ha = Distribuição != normal:p<=0.05
"""

import statsmodels
from statsmodels.stats.diagnostic import lilliefors

estatistica, p = statsmodels.stats.diagnostic.lilliefors(df['MEDV'], dist='norm')
print('Estatistica de teste: {}'.format(estatistica))
print('p-valor: {}'.format(p))

estatistica, p = statsmodels.stats.diagnostic.lilliefors(df['RM'], dist='norm')
print('Estatistca do teste: {}'.format(estatistica))
print('p-valor do teste: {}'.format(p))

"""**CORRELÇÃO LINEAR**

Pearson (Distribuição normal)

Spearman (Distribuição não normal)

Kendall(Distribuição não normal com quantidade pequena de amostras)

Ho = Não há correlação linear:p > 0,05

Ha = existe correlação linear: p <= 0,05
"""

#Pearson
coeficiente, p = stats.pearsonr(df.MEDV, df.RM)
print('Coeficiente de correlação: {}'.format(coeficiente))
print('p-valor: {}'.format(p))

#Spearman
coeficiente, p = stats.spearmanr(df.MEDV, df.LSTAT)
print('Coeficiente de correlação: {}'.format(coeficiente))
print('p-valor: {}'.format(p))

#Kendall
coeficiente, p = stats.kendalltau(df.MEDV, df.RM)
print('Coeficiente de correlação: {}'.format(coeficiente))
print('p-valor: {}'.format(p))

correlaçoes = df.corr(method='spearman')
correlaçoes

plt.figure()
sns.heatmap(correlaçoes, annot=True);

"""**REGRESSÃO LINEAR SIMPLES**"""

df.head(2)

x1 = df.iloc[:,0:1].values
x1

y = df.iloc[:, 3].values
y

from sklearn.model_selection import train_test_split
x_treino, x_teste, y_treino, y_teste = train_test_split(x1, y, test_size = 0.3, random_state = 10)

x_treino.shape, y_treino.shape

x_teste.shape, y_teste.shape

from sklearn.linear_model import LinearRegression

reg_linear1 = LinearRegression()
reg_linear1.fit(x_treino, y_treino)

# Intercepto (coeficiente linear)
reg_linear1.intercept_

#Coeficiente Angular
reg_linear1.coef_

"""**Equação: Valor = -626510,27 + 173771,45.número_cômodos**"""

#Coeficiente de Determinção dados de treino
reg_linear1.score(x_treino, y_treino)

#Coeficiente de Determinação de dados testes
reg_linear1.score(x_teste, y_teste)

previsoes_treino = reg_linear1.predict(x_treino)
previsoes_treino

import matplotlib.pyplot as plt

plt.scatter(y=y_treino, x=x_treino, color='blue', s=10, alpha=0.9)
X_plot = np.linspace(3, 9)
plt.plot(X_plot, X_plot*reg_linear1.coef_ + reg_linear1.intercept_, color='red')
plt.title('Reta de regressão')
plt.ylabel('Valor Médo')
plt.xlabel('Quantidade Média de Cômodos')
plt.show()

previsoes_teste = reg_linear1.predict(x_teste)
previsoes_teste

y_teste

plt.scatter(y=y_teste, x=x_teste, color='blue', s=10, alpha=0.9)
X_plot = np.linspace(4, 9)
plt.plot(X_plot, X_plot*reg_linear1.coef_ + reg_linear1.intercept_, color='red')
plt.title('Reta de Regressão')
plt.ylabel('Valor Médio')
plt.xlabel('Quantidade de Cômodos')
plt.show()

# Fazendo previsões para valores distintos
valor_casa = reg_linear1.predict([[6]])
valor_casa

"""**Métricas de Desempenho**"""

#Erro absoluto
abs(y_teste - previsoes_teste).mean()

from sklearn.metrics import mean_absolute_error,  mean_squared_error

#Erro médio absoluto
mean_absolute_error(y_teste, previsoes_teste)

#Erro quadratico médio
mean_squared_error(y_teste, previsoes_teste)

#Raiz do erro quadrático médio
np.sqrt(mean_squared_error(y_teste, previsoes_teste))

"""## Valor médio (MEDV) em função da classe social(LSTAT)"""

df.head(2)

x2 = df.iloc[:, 1:2].values
x2

y = df.iloc[:, 3].values
y

from sklearn.model_selection import train_test_split
x_treino, x_teste, y_treino, y_teste = train_test_split(x2, y, test_size=0.3, random_state=10)

x_treino.shape, y_treino.shape

x_teste.shape, y_teste.shape

from sklearn.linear_model import LinearRegression
reg_linear2 = LinearRegression()
reg_linear2.fit(x_treino, y_treino)

#Intercepto (coeficiente linear)
reg_linear2.intercept_

#Coeficiente Angular
reg_linear2.coef_

"""**Equação: Valor = 681977,75 - 17263,75.LSTAT**"""

#coeficiente de Determinação dados de treino
reg_linear2.score(x_treino, y_treino)

previsoes_treino = reg_linear2.predict(x_treino)
previsoes_treino

plt.scatter(y=y_treino, x=x_treino, color='blue', s=10, alpha=0.9)
X_plot = np.linspace(0, 40)
plt.plot(X_plot, X_plot*reg_linear2.coef_ + reg_linear2.intercept_, color='red')
plt.title('Reta de regressão')
plt.ylabel('Valor Médio')
plt.xlabel('Quantidade de Proprietarios de Classe Média Baixa (%)')
plt.show()

previsoes_teste = reg_linear2.predict(x_teste)
previsoes_teste

y_teste

#Coeficiente de Determinação
reg_linear2.score(x_teste, y_teste)

plt.scatter(y=y_teste, x=x_teste, color='blue', s=10, alpha=0.9)
X_plot = np.linspace(2, 35)
plt.plot(X_plot, X_plot*reg_linear2.coef_ + reg_linear2.intercept_, color='red')
plt.title('Reta de Regressão')
plt.ylabel('Valor Médio')
plt.xlabel('Quantidade de Proprietarios de Classe Média Baixa (%)')
plt.show()

#Fazendo Previsoes para valores distintos
valor_casa = reg_linear2.predict([[25]])
valor_casa

"""**Métricas de Desempenho**"""

#Erro absoluto
abs(y_teste - previsoes_teste).mean()

from sklearn.metrics import mean_absolute_error, mean_squared_error

#Erro médio absoluto
mean_absolute_error(y_teste, previsoes_teste)

#Erro quadratico médio
mean_squared_error(y_teste, previsoes_teste)

#Raiz do erro qurdrático médio(RMSE)
np.sqrt(mean_squared_error(y_teste, previsoes_teste))

"""## Valor médio (MEDV) em função da classe social(PTRATIO)

"""

x3 = df.iloc[:, 2:3].values
x3

y = df.iloc[:, 3].values

from sklearn.model_selection import train_test_split
x_treino, x_teste, y_treino, y_teste = train_test_split(x3, y, test_size=0.3, random_state=10)

x_treino.shape, y_treino.shape

x_teste.shape, y_teste.shape

from sklearn.linear_model import LinearRegression
reg_linear3 = LinearRegression()
reg_linear3.fit(x_treino, y_treino)

#Intercepto (coeficiente linear)
reg_linear3.intercept_

#Coeficiente Angular
reg_linear3.coef_

"""**Equação: Valor = 1249904,17 - 42872,50.PTRATIO**"""

#coeficiente de Determinação dados de treino
reg_linear3.score(x_treino, y_treino)

previsoes_teste = reg_linear3.predict(x_treino)
previsoes_treino

plt.scatter(y=y_treino, x=x_treino, color='blue', s=10, alpha=0.9)
X_plot = np.linspace(5, 25)
plt.plot(X_plot, X_plot*reg_linear3.coef_ + reg_linear3.intercept_, color='red')
plt.title('Reta de Pregressão')
plt.ylabel('Valor Médio')
plt.xlabel('Quantidade de Estudantes/Professores (%)')
plt.show()

casa_valor = reg_linear3.predict([[5]])
casa_valor